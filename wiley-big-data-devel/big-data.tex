\documentclass[letterpaper,man,apacite]{apa6}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}

\title{From big data to deep insight in developmental science}
\shorttitle{Big data in development}

\oneauthor{Rick O. Gilmore}
\twoaffiliations{The Pennsylvania State University, The Databrary Project}

\abstract{}

\authornote{Rick O. Gilmore is in the Department of Psychology, The Pennsylvania State University, University Park, PA 16802, rogilmore@psu.edu.
Any opinions, findings, and conclusions or recommendations expressed in the material contributed here are those of the author and do not necessarily reflect the views of the National Science Foundation, the Eunice Kennedy Shriver National Institute of Child Health and Human Development, or the Society for Research in Child Development.}

\begin{document}
\maketitle

\section{Introduction}

A search on the term ``big data'' yields more than 49 million hits on Google and 13 million hits on Bing.
The results return in less than a second.
The term yields more than 100,000 results on Google Scholar.
A search of the term using Google's ngram viewer (http://books.google.com/ngram) shows the first appearance of the term right before 1900 with a steady rise in frequency from the 1950s to just after 2000.
Google's ngram viewer indexes terms in digitized books.
So, whether measured by search engine matches of electronic documents available on the internet, scholarly documents, or digitized books, the term ``big data'' gets widespread use now.
That use has grown substantially over the past several decades.
The fact that these basic facts about a particular phrase can be determined in an instant speaks to the rapid pace of change in networked computing, search engines, and databases that has occurred largely in the last 20 years (https://en.wikipedia.org/wiki/List_of_websites_founded_before_1995).
``Big data'' has become a significant cultural phenomenon \cite{borgman_big_2015; boyd_critical_2012}, with frequent feature articles in the popular \cite{lohr_big_2012, Marcus2013} and specialist press \cite{HBR2015, Press2013a}.

In this paper, I focus on how the increased availability of and interest in analyzing large, complex, multi-level, multi-measure data sets has influenced, continues to influence, and promises to alter the study of human development.
I begin by asking what makes data especially big, and what implications the size, density, or complexity of datasets might have for understanding human development.
Then, I will briefly survey a set of case studies that illustrate how large, complex data sets have been and are being used currently to reveal the complexities of developmental processes.
To close, I will discuss a range of issues that the emergence of ``big data" approaches to developmental science pose for the future of the field.

I will argue against the claim that the emergence of an era of ``big data'' signals the end of theory \cite{anderson_end_2008} while acknowledging the lure of that notion to some.
Nor, do I find that ``big data'' analyses are all that new in developmental psychology.
Rather, I find that a while the promises of ``big data'' to revolutionize scientific understanding are exaggerated \cite{boyd_critical_2012}, developmental science tackles questions that can benefit substantially from larger, richer, more widely shared, and more readily interrelatable datasets.
Thus, whether significant novel insights into human development emerge from the era of ``big data'' depend not just on the size or complexity of the datasets, but on how widely and openly the data are shared, and how readily able researchers are able to combine or link datasets across levels of analysis.
In turn, these specific innovations depend largely on small, probably manageable, but nonetheless thorny problems related to policy, scientific culture, individual esearcher behavior, publisher priorities, and research funding levels.
Technology may have enabled the ``big data'' era, but the challenges it poses may turn out to be the least important, at least where advancing research in developmental psychology is concerned.

 \subsection{What Does `Big Data` Mean in Developmental Science?}

Doug Laney \cite{laney01controlling3v} was the first person to describe the dimensions of data streams that make them especially ``big'': Volume, velocity, and variety.
Data streams that are large in quantity, change rapidly, or consist of many distinct components merit special consideration \cite{ibm_2015}.
Of course, general statements about the total quantity of data generated per day \cite{ibm_2015} make little sense outside of a specific research context.

What is high volume data to a a developmental psychologist, an archive of 10 terabytes (TB) of video and flat-file data, for example, is tiny to a physicist working on the Large Hadron Collider (LHC) that generates 30 petabytes in a year \cite{CERN_LHC}.
Similarly, the measure of volume matters.
The Inter-university Consortium for Political and Social Research (ICPSR) \cite{ICSPR}, one of the largest data repositories for data from the social sciences, consists of more than 500,000 files in 16 specialized data collections \cite{ICPSR}.
Yet, until the recent acquisition of video data from the Gates Foundation-funded Methods of Effective Teaching (MET) Project \cite{METProject}, the large number of files in the repository totalled about 10 TB of digital storage.
Even more important than the quantity of information stored is the kind of information: What are the targets of inquiry?

Most developmental researchers study individuals or groups of individuals and families.
But, others focus on neighborhoods or schools, or even broader social, cultural, political and environmental influences.
This diversity in the targets of analysis reflects an implicit shared belief that developmental trajectories arise from a variety of influences organized at multiple levels of analysis and operating across multiple time scales.
Consequently, the aspects of `volume' most pertinent to developmental science include the number of participants or families or the number measurement time points.
We will see that many developmental studies involve tens of participants, but some notable datasets have hundreds or thousands of participants.
Similarly, the aspects of data velocity most relevant to developmental researchers are those related to the frequency or spacing of measurements.
In developmental research, velocity can span many orders of magnitude, from physiological measurements collected at millisecond time scales to longitudinal research spanning years or decades.
Variety encompasses both the range of measurement types employed across developmental research: biological, behavioral, contextual, and cultural/historical.
To the ``three Vs'', variability, or the rate of change over time, and complexity, the mutual interdependence of individual measures, might also be added.
For example, patterns of brain activity change rapidly, while working memory spans typically do not.
Brain activity and peripheral autonomic nervous system measurements like heart rate, heart period variability, and galvanic skin responses are related to central nervous system activity in causal, but indirect and complex ways. 

Conventional conceptualizations of data focus on text or numeric information, but increasingly images, and audio \cite{Mehl} and video recordings have become part of the mix of data streams collected by researchers and others to better understand human behavior.
Video in particular captures the complexity and richness of behavior unlike any other measure, and so video provides the main source of information for many researchers who study behavior in laboratory, classroom, or museum contexts. 
Images and recordings are both larger, in file size, and denser than text or flat-file data. 
Thus, developing tools that enable the storage and sharing of images, including brain images, audio, and video data has become a high priority for researchers and research funders \cite{Databrary2015, openfmri.org} and, of course, sharing these materials for non-research entertainment uses has become astonishingly popular \cite{YouTube2015}.
New technologies, specifically the widespread use of smart mobile devices with embedded sensors, promises to make new big data streams about individual participants' locations, physiological states \cite{Picard}, activity patterns, and momentary cognitive \cite{Sliwinski}, and emotional states broadly available to researchers.
Moreover, new web-based tools like Amazon's Mechanical Turk (http://www.mturk.com) or Apple's HealthKit (http://www.applehealthkit.com/) will make it possible for research teams to collect data from large numbers of participants in short periods of time, significantly enlarging the volume, velocity, and variety available for analysis.   
Fundamentally, big data are those that cannot readily be processed by traditional databases or systems that are widely familiar to developmental researchers.

Data may be big in any number of ways and present themselves in structured or unstructured forms, but they pose significant new challenges to traditional avenues for data creation, capture, storage, sharing, analysis, transfer, visualization, and analysis.
Big data may also magnify the challenges facing researchers in maintaining participant privacy, in part because the more data that are collected, the more likely it is that individual identities can be discovered \cite{sweeney_identifiability}.



\subsection{Big data about what and for what purposes?}

Armed with some definitions about what constitutes big data, we can next ask what topics large datasets can describe and help inform.
The answer spans the range of phenomena covered by developmental science, from genes to geography and from microseconds to millenia.
In the case studies to follow, we will highlight studies that focus on biological evidence from genes, brain structure and activity patterns, hormonal variation, nutrition, growth, and health.
Biological evidence may derive from typically developing or atypically developing populations or both.
% Add citations to examples %
Often, behavioral evidence accompanies biological evidence, sometimes featuring standardized task assessments.
But, there are many examples of big datasets consisting solely of behavioral data.
These provide evidence about patterns of change and stability across the range of phenomena that interest developmental researchers: perception, action, cognition, language, emotion, sleep, personality, temperament, friendship, family, play, school achievement, substance use, sexuality, and sleep.
Still other large datasets focus on educational and employment aptitudes and outcomes and the social, economic, political, cultural, and historical contexts in which children and youth come of age.
% Again find examples and cite %

Large datasets can demonstrate either human diversity or human universals, depending on the topic and area of focus.
In most cases, however, big datasets in developmental science serve to answer core scientific questions that drive research in this area: What develops? 
Why does it develop that way? 
Does the environment change or the person or both, and how so?
Big datasets enable more precise estimation of small effects, for qualities or conditions rare among individuals.
High volume or velocity data may inform the estimation of trends within or between people across time \cite{rietveld_replicability_2014}.
Developmental scientists have long recognized the multiple, nested influences on developmental processes arising at different temporal and spatial scales \cite{elman_rethinking_1998, gottlieb_normally_1998, oyama_ontogeny_2000, vygotsky_mind_1980}.
Only recently have the tools and resources needed to collect high volume, velocity, and variety needed to make many of these theoretical notions empirically testable.
Finally, many, perhaps most big datasets in developmental science have as a primary aim the understanding or treatment of disease or disorder.
In short, big data in developmental science focuses on answering the biggest, most important questions in the field.
In the next section, we turn to evaluating specific cases of research projects that have generated big datasets and data repositories that preserve, store, and share them with the scientific community.

\section{Case Studies}
 
\subsection{Biology and Health}

\subsubsection{Epidemiological and Population-based Studies}

Some of the largest and most widely used datasets in developmental science are population-based, often with an epidemiological dimension.
Several notable examples began data collection in the 1950's or 60's.
The National Health and Nutrition Examination Survey (NHANES) \cite{NHANES} began collecting data in 1959 with a focus on characterizing the health and nutritional status of U.S. infants, children, and adults. 
The annual survey combines interviews about demographic, socioeconomic, dietary and health related topics and physical examinations involving medical, dental, and physiological measurements, as well as laboratory tests.
The study assesses a nationally representative sample of about 5,000 persons located across the country, but 15 counties are surveyed annually.
Many will be familiar with some of the study's products such as standardized child growth charts (http://www.cdc.gov/growthcharts/cdc_charts.htm), or related initiatives such as the National Youth Fitness Survey (NNYFS) (http://www.cdc.gov/nchs/nnyfs.htm which collected data on physical activity and fitness levels in order to provide an evaluation of the health and fitness of children in the U.S. ages 3 to 15. 
The NNYFS collected data on physical activity and fitness levels of our youth through interviews and fitness tests.
Much of the NHANES and NNYFS data is available to the public through the National Center for Health Statistics at the U.S. Centers for Disease Control.
However, access to some data are restricted, available only to individuals via a Research Data Center (RDC) that can provide access.
<http://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?CycleBeginYear=1999&Component=Non-Public>.
There are 19 Federal Statistical Research Data Center (RDC) locations across the U.S.
A Google Scholar search shows more than 110,000 publications mention the NHANES dataset.
The Panel Study on Income Dynamics (PSID) \cite{PSID} is another large-scale population based effort.
PSID began in 1968 with a U.S. nationally representative sample of 5,000 families and more than 18,000 individuals.
The study consists of survey responses to questions about employment, income, wealth, expenditures, health, marriage, childbearing, child development, philanthropy, education, and other topics. As of mid-2015, PSID had generated more than 3,900 publications \cite{PSID_pubs}. 
Much of data is available publicly to users who register (http://simba.isr.umich.edu/U/ca.aspx) subject to the provisions of a formal set of use conditions (http://simba.isr.umich.edu/U/CondUse.aspx) that focus largely on ensuring that participants are not reidentified and that users properly cite and acknowledge use of the data. 
In addition, some restricted data elements are only available subject to a formal restricted use contract (http://simba.isr.umich.edu/restricted/RestrictedUse.aspx) between the investigator and the data owner, the University of Michigan.

In contrast the National Longitudinal Survey of Youth (NLSY) \cite{NLSY} has studied a large subset of the same cohort since the study began in 1979.
The project follows the lives of a sample of almost 10,000 American youth born between 1957-64.
Hosted by the U.S. National Bureau of Labor Statistics (BLS), NLSY ata are now available for up to 25 survey rounds on questions relating to employment and related questions.
The NLSY has also been extended to encompass women born in 1922-37 and 1943-55 and men born 1906-21 and 1941-52 through the National Longitudinal Survey (NLS).
Most NLSY and NLS data are available free of charge to by means of a web-based data portal \cite{NLSY_data}, access to which users must register for.
Users must apply for special permission to access geographic-related variables.
The Center for Human Resource Research (CHRR) at The Ohio State University and the National Opinion Research Center (NORC) at the University of Chicago administer both the data collection and repository functions.
A Google Scholar search in mid-2015 shows more than 20,000 publications cite the NLSY.

The Early Childhood Longitudinal Study (ECLS) is another large-scale population-based study that has followed the same groups of young people over time focusing on child development, school readiness, and early school experiences. 
The ECLS consists of three cohorts, one focused on a sample of children measured beginning at birth and two cohorts following children from kindergarten.
The birth cohort a sample of children born in 2001 and followed from birth through kindergarten entry, and unusual among comparable studies includes data from fathers. 
One of the kindergarten cohorts studied approximately 22,000 children who entered school in 1998-99 and were followe through the eighth grade. 
A second cohort entered kindergarten in 2010-11 and is being followed through the fifth grade.
The project has received funding from the National Center for Educational Statistics (https://nces.ed.gov/ecls/), and the data are archived at ICPSR.
ECLS consists of both public and restricted data, and according to a Google Scholar search has generated more than 8,000 publications, but ICSPR says 167.

The National Longitudinal Study of Adolescent Health (Ad Health) \cite{adolescent_health} was a survey designed to measure the multiplicity of influences on adolescents' health and unhealthy behaviors. 
Undertaken in response to a Congressional mandate, the study was carried out in two phases, the first involving surveys of 90,000 7-12th graders at 145 schools around the U.S. during the 1994-1995 school year. 
The second phase involved 20,000 participants, where both the target adolescents and their parents underwent interviews at two time points separated by a year. 
The Ad Health cohort has been followed into young adulthood with four in-home interviews, the most recent in 2008, when the sample was aged 24-32. 
In addition to survey data Add Health includes biomarker data from a blood test taken during Wave IV. 
Data are available about glucose, hemoglobin (HbA1c) levels, and blood lipids. 
The Add Health data \cite{harris_add_health} are archived at ICSPR \cite{ICPSR} and are available for public use.
As of mid-2015, more than 5,000 publications \cite{add_health_publications} had arisen from the Add Health dataset.

In comparison, the NICHD Study of Early Child Care and Youth Development (SECCYD) prospectively followed the experiences of 1,364 infants born at 10 locations throughout the United States in 1991.
The goal was to learn more about the kind and quality of child care experiences, and the effects of different child care settings on developmental outcomes. 
Measures included video, surveys and interviews, behavioral tests, biomarkers such as salivary cortisol, blood pressure, and anthropometric measures, and demographic information.
The study included multiple respondents, including the child, parents, caregivers, clinicians, and child care center directors.
Unlike the Ad Health study, data in SECCYD are not available to the public, but are restricted.
Access is granted only by application, and approval is granted on a case-by-case basis.
The SECCYD has generated more than 214 publications as of mid-2015 \cite{seccyd_publications}.

Outside the U.S., there are several examples of large-scale longitudinal studies focused on children's growth and health.
Launched in 2011, the Japan Environment and Children's Study <http://www.env.go.jp/en/chemi/hs/jecs/> is a birth cohort study involving 100,000 parent-child pairs with the goal of evaluating the impact of various environmental factors on children's health and development. 
Pilot studies started in 2008 and the hundred thousandth participating mother was enrolled in March 2014. 
Health outcomes and exposure measurements will continue until the participating children become 13 years old.
The study is in its early stages, and has only produced a handful of publications <http://www.env.go.jp/en/chemi/hs/jecs/publications/index.html>.
Data sharing plans have not been announced.
World Health Organization (WHO) has offered to help coordinate measurement strategies for large-scale birth cohort studies <http://www.who.int/ceh/cohorts/en/> to ensure that data can be harmonized across them.
Several birth cohort studies have been undertaken in the U.K., beginning with the National Survey of Health & Development in 1946 (https://en.wikipedia.org/wiki/National_Survey_of_Health_%26_Development). 
The National Child Development Study (NCDS) is a continuing longitudinal study that seeks to follow the lives of all those living in Great Britain who were born in one particular week in 1958. 
The origins of the NCDS can be found in the Perinatal Mortality Survey (PMS) which was then sponsored by the National Birthday Trust Fund and set up to collect information about the social and obstetric factors associated with stillbirth and death in early infancy.[3] Examples of other topics which have since been included are medical care, health, home environment, educational progress, parental involvement, family relationships, economic activity, income, training and housing.[4]
Conducted by the Centre for Longitudinal Studies (CLS), the aim of the study is to improve understanding of the factors affecting human development over the whole lifespan. 
It collects information on physical and educational development, economic circumstances, employment, family life, health behaviour, wellbeing, social participation and attitudes.
physical, educational and social development.[1] During the period 2002-2004, genetic information on participants was also obtained to examine the genetic effects on common traits and diseases.[2]
The British Cohort Studies have generated more than 3,500 publications (http://www.cls.ioe.ac.uk/Bibliography.aspx?sitesectionid=647&sitesectiontitle=Bibliography) to-date.
Data are available from (http://ukdataservice.ac.uk/get-data/key-data/cohort-and-longitudinal-studies) by registration.
Another widely known and used dataset comes from the World Health Organization's (WHO) Multicentre Growth Reference Study (MGRS) (http://www.who.int/childgrowth/en/).
The MGRS collected growth and related data from 8500 children from widely different ethnic backgrounds and cultural settings, specifically Brazil, Ghana, India, Norway, Oman, and the U.S.
The data provide body mass index, height for children 5-19, and weight data norms for children 5-10.

Not all large-scale birth cohort studies succeed.
A notable example in the U.S. is the National Children's Study](http://www.nichd.nih.gov/research/NCS/Pages/default.aspx).
Authorized by the Children's Health Act of 2000, the NCS would have followed 100,000 children from before birth to age 21. 
However, the NIH Director decided to close the NCS on December 12, 2014 following the recommendations of an advisory panel.
Authorized by the Children’s Health Act of 2000, the NCS was a planned large-scale, long-term study of U.S. children and their mothers and fathers designed to study environmental influences on child health and development. 
Questionnaire, physical measures, biospecimens and environmental sample data from up to 5,726 participants in the NCS Vanguard study were collected in 2009-2014 prior to the NCS study's closure.
Those data are slated for release in a data archive sometime in 2015. 

Several themes emerge from this sample of population-based studies.
Datasets are large in terms of the volume of participants sampled ranging in the thousands to tens of thousands.
The datasets demonstrate significant variety of measures, including survey-based and bio-marker-based (NHANES, Ad Health, SECCYD) and even video (SECCYD).
The studies show variety geographic composition, as well.
Some studies involve tens of sample occasions per individual, the NLSY and Ad Health studies in particular.
Datasets are housed either in U.S. Government (NHANES, SECCYD) or university-based repositories (PSID, Ad Health, NLSY).
Most data are available to the public via web-based download or browsing/analysis portal, although access to data deemed sensitive may require a specific application and approval and possibly travel to a Research Data Center.
Finally, the datasets have generated research publications that range from the hundreds to the tens of thousands, suggesting that the collection, curation, and preservation of these resources has had a significant impact on scientific discovery.
% Susan McHale's comment about training. Check the other datasets for this.
% Limits on geographic linkage, other ways data are anomymized to reduce possibility of identifiability.

\subsubsection{Behavior Genetics}

The next area of developmental science we explore is behavior genetics, where large data samples have long been required in order to detect what can often be small effect sizes.
Several large-scale genetics studies that are not specifically developmental deserve mention.
The Genome of the Netherlands Project(http://www.bbmri.nl/en-gb/activities/rainbow-projects/131-genome-of-the-netherlands) is a publicly available dataset from n=250 families, consisting of two parents plus one of their adult children \cite{Genome_Netherlands}.
The Genes, Environment, and Melanoma Study (GEMS) focuses on risk for melanoma in a sample of 3,700 individuals from the North America, Europe, and Australia (http://gemstudy.org/main/index.html).
The Psychiatric Genomics Consortium (PGC) (http://www.med.unc.edu/pgc) contains data from more than 170,000 individuals who have psychiatric diagnoses or are considered at-risk.
Many disorders featured (autism, attention-deficit hyperactivity disorder, and schizophrenia) in the PGC dataset have developmental dimensions.
Genome-wide association study (GWAS) results from the PGC dataset may be viewed in a specialized web browser tool (http://www.broadinstitute.org/mpg/ricopili/).

The U.K.-based Twins Early Development Study (TEDS) \cite{TEDS} (https://en.wikipedia.org/wiki/Twins_Early_Development_Study) contains survey data from 15,000 English and Welsh families who gave birth to twins between 1994 and 1996.
Some 13,000 pairs remain actively involved, providing lab-based behavioral task and survey responses.
DNA samples from more than 5,000 twins pairs are also available.
TEDS has generated more than 350 publications to-date.
Researchers wishing to gain access to the data may do so by submitting a formal data request specifying the aims of the planned research and the variables that needed satisfy the aims. 
Proposals that do not overlap with analyses already being planned or carried out by the TEDS research team or other collaborators are usually approved.

The Twin and Offspring Study in Sweden (TOSS) \cite{TOSS} focuses on genetic and environmental contributions to measures of family relationships and mental health.
TOSS extends the Twin Moms Project to include a sample of twin fathers (N=320 twin pairs and their families).
In addition, TOSS plans to collect another 250 pairs of twin mothers for a target sample of 900 twin parents (n=3,000 individuals) and their families.
While still relatively early in data collection, more than 24 publications reference the TOSS dataset.
Data sharing plans have not yet been announced.

Illustrative U.S. examples include the Colorado Adoption Project (CAP), the Nonshared Environment in Adolescent Development (NEAD) project, and the Early Growth and Development Study (EGADS).
NEAD studied a sample of 720 families, including twins, siblings, and their parents, in a longitudinal design that involved up to 3 data collection waves.
Researchers focused on survey, self-report, and experimenter ratings (from video) of family relationships, adolescent adjustment and competence.
A Google Scholar search shows 73 publications to-date.
The data will be shared by request to the project team.
The team plans to share the data openly later in 2015.

Adoption studies provide a unique window on the mix of genetic and non-genetic factors that influence child development.
Since its inception in 1976, the Colorado Adoption Project (CAP) (http://ibg.colorado.edu/cap/index.html) has enrolled more than 2,400 participants from more than 450 families.
Data include cognitive abilities, temperament measures, demographic variables, 
Additionally parents completed a questionnaire assessment which included measures of temperament
CAP has generated more than 200 published articles (http://ibg.colorado.edu/cap/publishedarticles.html).
Data collection continues.
The study aims to be the definitive genetically informed longitudinal study of lifespan development \cite{rhea_colorado_2013}.
Data from 1976-1989 are archived at Dataverse (https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/00913) and can be accessed by application to Dataverse.
EGADS is a prospective adoption study of (n=561) triads of birth parents, adoptive parents, and adopted children in the U.S. 
The study focuses on genetic and non-genetic factors that influence children’s adjustment from infancy to age 9. 
The data include self- and other-report measures, DNA, and salivary cortisol.
Data are available by request, with plans for more open data sharing in the near future.

\subsubsection{Brain Imaging}

Several large studies have focused on developmental patterns in brain structure or activity.
For practical reasons -- motion artifacts make imaging very young children extremely challenging -- most projects have focused on children and adolescents.
One of the earliest studies of its kind was a combined longitudinal and cross-sectional study of child and adolescent structural brain development led by Jay Giedd at NIMH \cite{giedd_brain_1999}.
The study collected structural brain information from 145 4 to 20-year-olds along with behavioral and clinical data.
More than 100 of the participants were scanned on more than one occasion, with the time between scans approximately two years.
The original paper describing this study has been cited more than 3,300 times, as of mid-2015.
The dataset has generated other highly cited papers \cite{gogtay_dynamic_2004}, but the data appear not to be available for analyses by researchers outside the original investigative team.
The NIH MRI Study of of Normal Brain Development \cite{NIH_Pediatric_MRI} collected multi-modal structural MRI from 554 children from 4 to 18 years of age.
A second cohort of children from birth to 4 years was scanned longitudinally with up to 10 scans. 
Demographic, hormonal, cognitive, affective, and psychiatric data were also collected.
The data are available to qualified researchers by application, and the dataset has generated some highly cited papers since data collection ended in 2006 \cite{group_total_2012, zielinski_network-level_2010}.
John Richards and colleagues have combined data from the NIH MRI Study, data collected in their own labs, and other public sources to create average structural brain templates that can provide more accurate bases for developmental functional neuroimaging studies using EEG and fMRI \cite{Richards_Developmental_MRI_Database, richards_database_2015}.
These data can be openly shared with appropriate citation.
More recently, the Pediatric Imaging, Neurocognition, and Genetics (PING) Project \cite{PING} collected multimodal neuroimaging data, genotypes, neurodevelopmental histories, and information about cognitive and social and emotional function in more than 1,000 participants 3-20 years of age recruited from Baltimore, Boston, Honolulu, Los Angeles, New Haven, New York, Sacramento, and San Diego. 
The study was funded by the Eunice Kennedy Shriver National Institute of Child Health and Human Development.
Data are available to the research community by application.
As of mid-2015, the project had generated more than 20 publications.
The Developmental Connectome Project \cite{developmental_connectome}, led by investigators at King’s College London, Imperial College London, and Oxford University goes against the trend of imaging studies that focus on older children.
This project aims to study the connectome, a map of human brain connectivity, from 20 to 44 weeks post-conception.
Funded by the European Research Council, the imaging data are accompanied by clinical, behavioral and genetic information.
Investigators hope that the data set will provide a basis for studying genetic and environmental risks that could lead to neurodevelopmental disorders such as Autistic Spectrum Disorder or Cerebral Palsy.
The project has already generated 17 publications as of mid-2015.

Looking across the set of large-scale pediatric brain imaging studies described here, several themes emerge.
One is that these studies require large, complex research teams, usually spanning multiple sites.
Another is that, with some notable exceptions \cite{richards_database_2015}, when the data are available for use by others, that use is controlled by the original investigative team.
In some cases, the original investigative team must be included as an author on any publication.
Another trend among large-scale developmental imaging studies is that the data are usually housed locally, on project-specific sites and not generally on centralized servers that aggregate data across studies and sources \cite{openfmri.org, neurovault.org}.

\subsection{Behavior}

In the realm of behavior, there are a number of measures that have become standards whose widespread adoption has resulted in data that are large in volume, velocity or variety.
Davida Teller pioneered empirical techniques for measuring visual acuity in preverbal children, and the use of Teller Acuity Cards has resulted in the publication of age-based norms for visual development in infants to four-year-olds \cite{mayer_monocular_1995} based on a sample of more than 400.
A companion study on children in Brazil \cite{salomao_large_1995} was conducted with an even larger sample.
The Bayley Scales of Infant and Toddler Development \cite{bayley2006bayley} arose from the Nancy Bayley's Berkeley Growth Study \cite{jones_berkeley_1941} that studied the behavior, motor coordination, physical activity, cognitive function, and maternal behavior of 61 healthy newborn infants.
The California First Year Mental Scale \cite{bayley1933california} and The California Infant Scale of Motor Development \cite{bayley1936california} the precursors.
The Bayley is widely used in clinical and epidemiological settings such as the EPICure <http://www.epicure.ac.uk/> because of the norms.
However, data about those norms appears to be under the control of the Pearson Publishing company that publishes the Bayley and licenses its use.
Bayley score data are available from the Carolina Abecedarian Project and the Carolina Approach to Responsive Education (CARE), 1972-1992 project on ICPSR (http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/4091?sortBy=19&amp;q=Bayley&amp;searchSource=revise).
The data are freely available to registered users of ICSPR. 

The Wechsler intelligence tests were developed by Dr. David Wechsler, beginning in the 1930's. The Wechsler Intelligence Scale for Children-III (WISC-III) is designed for children ages 6 - 16, while the Wechsler Preschool and Primary Scale of Intelligence-R (WPPSI-R) is designed for children age 4 - 6 1/2 years.
The current version (WISC V) is provided by Pearson (http://www.pearsonclinical.com/psychology/products/100000771/wechsler-intelligence-scale-for-childrensupsupfifth-edition--wisc-v.html).
Data about the norms themselves appears not to be available to researchers.
However, data from the Project on Human Development in Chicago Neighborhoods (PHDCN) that collected WISC-R data on 6,000 children, adolescents, and young adults is shared at ICSPR (https://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/13604?q=wisc&amp;searchSource=find-analyze-home&amp;sortBy=). 
The data are restricted, and thus are only available by specific authorization.
The Family Life Project also collected and reported WPPSI data.

There are several large-scale datasets associated with language processing.
The CHILDES/TalkBank \cite{macwhinney_childes_2001} archive is one of the largest and most well-established.
It consists of transcripts and audio and video recordings of children's utterances along with recent data from adults with aphasia.
CHILDES/TalkBank has generated more than ten thousand of citations, according to Google Scholar, and the data are available to the research community, some of them publicly.
The Human Speechome Project (http://www.media.mit.edu/cogmac/projects/hsp.html) at MIT's Media Lab involved recording 10 hours of audio and video from one child's home on a daily basis from birth to age three.
The project has generated more than 78 publications (http://www.media.mit.edu/cogmac/publications.html), but the data have not been made available outside of the original investigative team.
Data was gathered at an average rate of 200 gigabytes per day, necessitating the development of sophisticated data-mining tools to reduce analysis efforts to a manageable level, and transcribing significant speech added a labor-intensive dimension.
% edit previous
WordBank (http://wordbank.stanford.edu/) is an open access archive that consists of data from more than 40,000 adminstrations of the MacArthur-Bates Communicative Development Inventory (CDI).
Catherine Tamis-Lemonda has released video data (https://nyu.databrary.org/volume/8) from a longitudinal study of child language consisting of more than 1,000 sessions of infants and children (9 mos-7.6 years) and their mothers carrying out a series of semi-structured tasks.
The LENA Foundation has created a technology framework that allows children's speech in natural settings to be recorded and analyzed (http://www.lenafoundation.org/customer-resources/videos).
LENA stands for Language ENvironment Analysis.
The system provides an automatic language collection and analysis tool for speech language professionals and parents.
The system was designed and is distributed by the LENA Foundation.

%- Infant Behavior Questionnaire, CBC
While no archive for IBQ data across studies exists, IBQ data on 1,388 participants (n = 658) who were group matched within site with a group of non-exposed comparison infants (n=730) are archived at ICSPR (http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/34312?sortBy=19&amp;q=infant+behavior+questionnaire&amp;searchSource=revise) as part of the Maternal Lifestyle Study in Four Sites in the United States, 1993-2011.
MSL was a large NIH longitudinal studies of children with prenatal cocaine exposure (PCE). MLS was a longitudinal multi-site observational study of the long-term effects of in-utero exposure to cocaine on child development.
IBQ data are also available from ICPSR from the Family Life Project (http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/34602?sortBy=19&amp;q=ibq&amp;searchSource=revise).

\subsection{Education and Employment}

There are several large datasets with information about employment patterns and educational attainment in children and youth
The Bureau of Labor Statistics reports data about youth employment and unemployment patterns derived from the Census Bureau's Current Population Survey (http://www.bls.gov/cps/demographics.htm).
The U.S. Department of Education's National Center for Educational Statistics (NCES) collects and analyzes statistics on American primary, secondary, and post-secondary education, and many of the datasets are either public; data with individually identifiable data are available to researchers only under a restricted use agreement.
The College Board shares SAT and college cost and scholarship data with the research community by application (http://www.collegeboard.com/inquiry/csinquiry_form.html).
The ACT (http://www.act.org/research/). Privacy policies (http://www.act.org/privacy.html). 
The Trends in International Math and Science Study (TIMSS) studied mathematics and science achievement in 4th and 8th grade for more than 20 years.
Its sister study, the Progress in International Reading Literacy Study (PIRLS) has been studying reading achievement at the 4th grade.
Both studies provide data available for public download (http://timss.bc.edu/).
The 1999 TIMSS video study examined teaching practices in seven countries, and some of the materials are available for public use (http://www.timssvideo.com/).
The Measures of Effective Teaching (MET, http://www.metproject.org/) Project videotaped more than 3,000 classroom teachers beginning in 2009, with follow-on studies continuing today.
The MET video data are stored and shared at ICSPR.
The OECD-funded PISA dataset is available (http://pisa2000.acer.edu.au/index.php).
Data from the performance of students in Massive Open Online Courses at Harvard and MIT are available to the research community by application.  

The 
LearnLab!

          %      * Attitudes
   %          - Judith Torney-Purta, <http://www.nie.edu.sg/research-publications/cieclopediaorg/cieclopediaorg-a-to-z-listing/Judith-Torney-Purta>

\subsection{Social, Economic, and Cultural Contexts of Development}

       %  * [Family Life Project](http://flp.fpg.unc.edu/)

       The purpose of this project is to study the early development of a group of children who are at risk regarding later successful adjustment and for whom we have little information: children living in rural, largely poor communities. A birth cohort of 800 children in three rural counties of North Carolina and 600 children in three rural counties of Pennsylvania were studied over the first 3 years of life.
       https://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/34602?sortBy=&amp;q=Bayley&amp;searchSource=revise


MacArthur Network on Transitions to Adulthood (http://www.transitions2adulthood.com/). Data not obviously open or available.
Research Network on Adolescent Development & Juvenile Justice - See more at: https://www.macfound.org/networks/research-network-on-adolescent-development-juvenil/#sthash.PQOwqv14.dpuf
Research Network on Youth and Participatory Politics - See more at: https://www.macfound.org/networks/research-network-on-youth-and-participatory-politi/#sthash.egU1Wwvy.dpuf

       %  + Normative vs. perturbed development
       %      * Bucharest Early Intervention Project (BEIP), <http://www.childrenshospital.org/beip>
       %      * NPR story, <http://www.npr.org/blogs/health/2014/02/20/280237833/orphans-lonely-beginnings-reveal-how-parents-shape-a-childs-brain>

\section{The Future of Big Data in Development}

Clearly, the collection, analysis, and sharing of large, multilevel datasets has been part of the fabric of developmental science for a long time.
In this section, we discuss a range of technical, conceptual, and theoretical issues that arise in thinking about the future of big data in developmental science. 

\subsection{Technical}

Technical issues associated with big data in developmental science center on collection, storage and retrieval, data management, provenance, and analysis. 

\subsubsection{File and Data Formats}

\subsubsection{Collecting data with new technologies, data streams}

As described previously, developmental scientists have and continue to collect data at multiple levels of analysis, from genetic, endocrine, and metabolic measures to physical structure, brain activity, behavioral measures, to peer, family, school, neighborhood, and geographic/cultural context information.
Some researchers believe that advances in understanding about many development processes will require deeper understanding about how these influences combine to influence trajectories of change.
If true, achieving that understanding will require continued improvements in the mechanisms of measurement, and the tools for converting these measures into electronic data that can be cross-linked and analyzed.

For some some data elements, the devices used to make measurements already provide data and metadata in a structured, organized way.
For example, genetic analyses from modern gene sequencing tools provide machine-readable outputs that (Rick talk to David Vandenburgh).
Researchers who analyze hormone levels in saliva or micronutrients in blood, for example, (Rick asking Sam Scott, others).
Magnetic Resonance Imaging (MRI) systems produce electronic image data and machine-readable subject-level metadata; however, many research teams limit the amount and kind of subject-level metadata they enter into MRI databases because of the possibility of violating research participant confidentiality.
Physiological measurements like EEG, heart-rate or skin conductance, produce electronic files of the time series of measurements.
But, unlike MRI, there are no standard file formats, and most data collection systems provide no standard subject-level metadata.
Thus, the files require significant post-collection data processing prior to analysis. 
Behavioral measures involving computer-based tasks are commonly used in developmental research.
But, like physiological measures, many, if not most of these measures involve the use of custom, project-specific software, so the output data files, while often in an electronic form, may or may not be produced in a form that can be easily linked with other data items without significant post-processing.

Recordings such as still images, audio, and video are readily collected or converted to an electronic form.
There are a number of still image formats, but readily available tools exist to convert between them.
Audio and video provide a bigger challenge because of the diversity of formats.
Data archives like Databrary that specialize in video, for example, have chosen to convert all video into a common format in addition to storing files in their original formats for preservation purposes.

At the same time, many, perhaps most developmental researchers continue to collect data elements using paper and pencil measures, making some form of manual data entry essential.

Looking ahead, there is increasing use of web-based tools for data collection (Qualtrix, SurveyMonkey).
Amazon's Mechanical Turk (http://mturk.com), for example has become a hub for conducting large-scale behavioral science experiments, (see also Todd Gureckis' Psyturk).
Amazon's terms of use prohibit minors, but some developmental researchers have found ways to carry out studies that require parental consent.
The LookIt platform developed at MIT allows parents to give video-based informed consent for their child to participate in a behavioral study, such as one involving the measurement of looking times via a laptop or tablet computer's built-in web cam.
A number of researchers have adapted smartphones to serve as devices to collect survey, behavioral/task-related, and ambient sound information (Sliwinski, Mehl)

Other social media providers like Twitter, Facebook, Snapchat, Instagram, and YouTube collect individual data and metadata.
Services are free, so business model involves selling data.
Apple's HealthKit.
Other wearable devices like FitBit, Mio, collect data and store it in a private, proprietary cloud server.
Data is electronic, but data may or may not be accessible to user.
You can see what data Google has about you.
New initiatives like DataWallet (https://www.datawallet.io/) are on the horizong that may empower individuals to share their data for a fee.

Both old and new data collection systems raise a number of issues.
How can critical metadata be captured more efficiently without significantly increasing risks to privacy.
Video cameras that record recording date and time and camera specs, for example.
Reduce need for post-processing of data, more widespread use of tidy and reproducible data formats.
Non-proprietary data streams and storage.
Raise ethical questions about who owns data.

\subsubsection{Storing and Sharing big data}

Big data requires large scale servers.
If the data are to be served over the web, then the servers require signficant network bandwidth, and all of the other substantial infrastructure required of large-scale data centers.

Researchers who wish to find and reuse or store and share data face a bewildering array of options.

\subsubsubsection{Storing and Sharing Data}

The options include individual or institutional websites, or cloud services like Dropbox, Box, or Amazon Storage services.
Other researchers may choose institutional archives like Penn State's ScholarSphere (https://scholarsphere.psu.edu/).
There are domain specific archives like ICSPR, Databrary, TalkBank, or WordBank, or , OpenfMRI and NeuroVault.
Other researchers may choose to store and share their data with domain-general services like Researchgate.net, FigShare/SlideShare, Dataverse, or the Open Science Framework.
Other researchers are turning to open source web sites like GitHub.
Some journals offer or require storage of datasets, but these are typically limited to text-based flat-files used for statistical analyses and not raw images, videos, or physiological time series.
What to store, when to store (during, after), and how to share, how to get credit/notice/citations for sharing.

\subsubsubsection{Finding Data}

The task confronting researchers who wish to find and reanalyze or reuse data faces challenges, as well.
How to discover data?
What are the key terms? Demographic variables like age and sex. Task, context, language?
Data associated with specific publications, grants, or researchers.
Obviously repositories.
But, can we find the data we want?
Governments also maintain data archives such as the National Database for Autism Research, the National Center for Educational Statistics, the U.S. Census Bureau, the Centers for Disease Control, and the Bureau of Labor Statistics, to name a few sources of developmental science-related data discussed in this paper.
A number of large-scale research project maintain their own data repositories.
ICSPR, for example, enables variable-level searching, but not all datasets provide it.
The International Cross Time Cross System Dataset (XTXS) (http://www.intledstatsdatabase.org/) aspires to provide a comprehensive source of data about educational outcomes.
The APA maintains a web-page with links to datasets (http://www.apa.org/research/responsible/data-links.aspx).

It is much easier to find publications and search the network of references than it is to find data.

Rick's case study in trying to find and download a public dataset from ICPSR.

Bring data to the analyst or analyses to the data?
Problem will get bigger as datasets grow in size, complexity.

\subsubsection{Coding and analyzing big data}

Most data science work involves `janitor work' (http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html?_r=0) or data carpentry (http://datacarpentry.org/).
Turning raw materials into numbers.
How were the materials converted into numbers?
Data provenance.
Term definitions, coding books.
Example, from video to coded spreadsheets to numbers.

Emerging sentiment around the use of tools that enable reproducible science.
RStudio, Jupyter.
Version control.
Text-based, automated/scripted workflows. Galaxy?
Scripting in Datavyu.

Need for tools and workflows that keep track of the history of researcher's actions.
MS Word's track changes, but for data cleaning, coding, analysis.

\subsection{Ethical, Conceptual and Theoretical Issues}

The collection, analysis, and interpretation of large scale datasets poses a number of ethical, conceptual and theoretical issues.

\subsubsection{Ethics and Privacy}

Developmental researchers often collect data from vulnerable populations of research participants.
Professional ethics require that special care be taken about what data are collected from research participants in general and who gains access to it.
The focus in developmental science on studying vulnerable research populations magnifies these concerns.

Differing practices across cultures in terms of privacy pose challenges for collecting and aggregating datasets.
In the U.S., researchers must navigate a regulatory environment in which different types of data are covered under different sections of Federal law.
For example, the Federal Educational Rights and Privacy Act (FERPA - http://www2.ed.gov/policy/gen/guid/fpco/ferpa/index.html) governs who has access to a student's educational records.
The Health Insurance Portability and Accountability Act (HIPAA - http://www.hhs.gov/ocr/privacy/hipaa/understanding/), among other functions, governs the process by which individually identifiable health information may be disclosed and to whom.
If the data in question are audio or video recordings, different state provisions can come into play.
For example, in two-party states \cite{http://www.dmlp.org/legal-guide/recording-phone-calls-and-conversations} both the person making the recording and the person or persons being recorded must consent.

Research activities funded by the U.S. Federal Government, typically in colleges, universities, or academic or private medical centers, are supervised by an Institutional Review Board or its equivalent.
These entities are regulated by the U.S. Office of Health and Human Services (http://www.hhs.gov/ohrp/).
Researchers supervised by IRBs must respect privacy, secure informed consent or assent, and maintain confidentiality. 
Adhering to these ethical principles has practical consequences for research.
Researchers have limits on the ways they are able to recruit and identify participants.
Minors must give informed assent to participate in a study with a parent or guardian giving formal consent.
Data must be collected in ways that minimimize the likelihood that information given by a participant will be disclosed or a participants' identity revealed outside the research team.
This usually means that data items that could reveal a participant's identity are removed or altered to reduce the likelihood of disclosure.
Whether `de-identified' data of this sort can be shared with researchers outside the original team that collected depends on several factors.
One factor is the sensitivity of the data collected and the likelihood that specific identities or home locations or other items could be revealed.
Another factor concerns whether participants were informed that de-identified data might be shared outside the research team.
IRBs may view these matters differently, creating additional complexities.
Some IRBs may require participants to be informed that de-identified data might be shared outside the IRB-approved research team, and others may deem the analysis of de-identified data as no longer meeting the definition of human subjects research.
From a big data perspective, if data cannot be shared outside the original IRB-approved research team, then the possible analyses are restricted to the interests, resources, and expertise of that team.
% What about population data......

Of course, some data types like photographs, audio or video recordings contain identifiable information that cannot be removed or altered without reducing the value to others.
Thus, data from photographs or recordings requires additional consideration and special care.
Databrary (http://databrary.org), a digital data library specialized for storing, managing, and sharing video data from developmental research has an access model that empowers researchers who wish to share identifiable research data to do so with explicit permission of the participants.
Databrary has created template language to help researchers gain participants' permission.
Further, Databrary restricts access to its identifiable data to researchers who have formally agreed to uphold ethical research principles and whose institutions approve of their access.
The notion that research participants can consent to share identifiable or potentially identifiable data is relatively new.
The Personal Genomes Project, Open Humans Project, and Human Connectome Project embody similar principles.
The experience of Databrary investigators is that a significant proportion -- more than 75 percent -- of research participants and their parents or guardians will consent to sharing identifiable data, mostly video, with other members of the research community.

It is too early to predict whether it will become commonplace for academic developmental researchers to seek explicit permission to share research data, including identifiable elements, with other researchers.
There are reasons to be optimistic, however.
In just over a year of operation, Databrary has secured formal agreements with more than 75 institutions in North and South America, Europe, Australia, and Asia allowing more than X researchers to access identifiable data.
On the other hand, some leading developmental researchers have argued that the families of research participants forge a relationship of trust with a particular research team, formalized through the informed consent document \cite{Eisenberg-APS}.
The relationship might be harmed or the research project negatively affected if participants were asked to share data with other researchers.
Sensitive to the latter argument, Databrary has recommended that permission to share be sought separate from consent to participant in research and after a given data collection has ended.
Moreover, the fact that a significant proportion of families agree to share when asked suggests that the relationship of trust involved in research participation might be extended to a community of researchers, given suitable provisions and constraints.
Undoubtedly, seeking explicit permission to share on a consistent and widespread basis would resolve any ambiguity about whether a given dataset can be shared with whom and for what sort of purposes.

Greater transparency and more explicit clarification about what data is being collected and for what purposes could be sought from commercial entities, as well.
Social media companies like Google, Facebook, Twitter, SnapChat, and Instagram have business models that involve the collection, mining, and packaging of data, usually to advertisers, in exchange for services that are free to users.
While some services attempt to restrict the youngest ages at which users can create accounts, the limits often lack rigor, and there is no parallel to the requirement of adult consent required in formal research contexts.
The data collection and analyses carried out by private entities are subject to no supervision or formal regulation comparable to academic researchers.
Instead, data use, analysis, and sharing provisions are governed by terms of use agreements users must indicate agreement with, usually by clicking a button, prior to using a given service.
Unlike academic settings, where violations of research ethics principles may involve significant consequences for the researchers and institutions, violations of commercial terms of use require aggrieved parties to seek redress through litigation.
The software industry has recommended its members adopt common data privacy principles \cite{}, but these guidelines are voluntary.

Summary.
Many big data sets have restrictions on them, aren't permissioned for open, widespread sharing
Must be used at Restricted Data facilities, can't be used to study individuals.
Studies of individuals may or may not have permission to share widely.
New models for gaining permission to share identifiable data on a restricted basis may expand the availability of big data for data reuse.
Have to ensure that data reuse is not prohibited by formal consent process.
Have to ensure that data don't have to be destroyed.
Remaining concerns about possibility that data linkage increases the risks of reidentification.
There are questions about whether it is essential to reconsent minors when they become adults.
Reconsenting may be impractical.
General concern about whether it is possible to consent to sharing of an indefinite nature.
Security can't be guaranteed, so risks can be minimized, but not reduced.
Files that are downloaded increase risks, for image streams, it is impractical to prevent image/sound capture.
Principle of informed consent important to uphold.
Not clear how fully informed consumers are in using free commercial services.

\subsubsection{Transparency and Reproducibility}

The social and behavioral sciences have seen a string of high profile cases of scientific misconduct in recent years, including cases of fraudulent data \cite{}.
The credibility problem is magnified by several factors.
That lack of power and unrestricted exploratory analyses may mean that most research findings are false \cite{Ioanides}.
The actual effect sizes of published findings is unknown due to a bias toward publishing positive results.
Most journals reject papers that report failures to replicate published findings, and as a result, few scientists attempt or are recognized and rewarded for conducting genuine replications \cite{Nosek-Spies}.
The problem is so serious that some have claimed that science as a whole faces a crisis of replicability.

To address the crisis, the Center for Open Science (http://cos.io) has organized several large-scale replication efforts, including some in psychological science under the umbrella of the ``Many Labs'' project \cite{klein, https://osf.io/ct89g/; https://osf.io/8cd4r/}.
The results of these pre-registered, open, large sample replications have been mixed.
Some published effects clearly replicated, but others did not.

Whether there are replicability problems developmental science and whether they constitute a crisis is not known.
Developmental research reflects the same positive effects biases seen in other fields, and the same problem that null results often sit unpublished in file drawers -- the so-called file drawer effect \cite{rosenthal_file_1979}.
No failures to replicate developmental studies have been reported to Psychfiledrawer.org (http://psychfiledrawer.org/view_article_list.php), a resource designed to bring replications failures to light.
As some developmental researchers have written (http://deevybee.blogspot.co.uk/2012/01/novelty-interest-and-replicability.html), replicating effects with developmental populations can be especially difficult and so even partial replications are noteworthy.
No large-scale replication efforts in developmental science have been mounted, but there have been calls for changes in journal practices to give replications have a more privileged place in scientific publications (http://deevybee.blogspot.co.uk/2012/01/novelty-interest-and-replicability.html).
One barrier to more open data practices appears to be researcher's fears of having one's reputation or abilities publicly undermined \cite{ascoli_ups_2006}.
So, changing views about replication may require shifts in the scientific culture.
Researchers should work to reduce the extent of blame levied at researchers whose initial positive findings fail to be replicated by others (http://deevybee.blogspot.com/2015/07/publishing-replication-failures-some.html).
Technological tools that foster increased openness and transparency and more systematic research data management (OSF and Databrary) will also contribute to changing the scientific practices.
So will the widespread adoption of more consistent journal practices related to transparent and open scientific practices \cite{nosek_promoting_2015}.

Still, the increasing availability of large-scale datasets about developmental questions promises to magnify problems at the intersection between exploratory and confirmatory research.
Large volume, higher velocity or variety datasets make it possible to explore and discover novel unpredicted patterns in data.
But, novel findings might be spurious, and exploratory findings must be properly confirmed.
While pre-registration and pre-review have been suggested as one way to address the problem of spurious exploratory findings, these tools may not be practical in all cases and could have a chilling effect on discovery.
In contrast, increased transparency about the process that led to an exploratory finding and the steps taken to confirm it can bolster a finding's credibility.
Thus, developmental researchers may find it essential to adopt more transparent and reproducible workflows using some of the new tools developed for this purpose (COS; Databrary).

\subsubsection{Community Engagement and the Impetus for Change}

Developmental researchers have clearly shown enthusiasm for sharing with the research community and the public at large the results of their findings via publications, and in some subfields the sharing of data, materials and methods is firmly established.
Open sharing practices tend to be more common when there is a high cost, centralized source of scientific data that could not conveniently be owned or managed by researchers themselves (e.g., space telescopes or the U.S. Census).
Successful big data projects -- repositories or specific studies or datasets -- appear to have fostered a high level of engagement around a particular resource, often through specific training, and targeted workshops (e.g. Ad Health, ICSPR, Databrary, AERA workshop on video data sharing, COS, Data/Software Carpentry).
In addition to bottom-up/grassroots initiatives, journals and funding agencies continue to play a vital role in creating an impetus for change.
Funders can require data management plans, mandate data be deposited into particular types of open repositories (Gates Foundation; NIMH call), and provide funding to build and support big data infrastructure.
Journals can also require that data be deposited in open archives as a condition of publication in addition to adopting other transparent and open science practices for manuscripts they accept.
However, the problem with data sharing mandates from funders is that there is no specific funding mechanism to provide sufficient ongoing financial support for data archives, and few researchers budget funds to support data management and archiving.
And, while some journals are willing to take on the burden of storing and sharing data associated with publications, others (Journal of Neuroscience) have gone the other way.
Thus, in the interests of promoting greater openness and transparency, funders and journals may create unfunded mandates that make it harder for researchers to make discoveries.
For example, new regulations about when data must be deposited may be unwieldy and impractical for developmental scientists. 
See Nancy Eisenberg piece on data sharing. (https://www.psychologicalscience.org/index.php/publications/observer/2015/may-june-15/thoughts-on-the-future-of-data-sharing.html).
APA stance on data sharing. (http://www.apa.org/science/leadership/bsa/data-sharing-report.aspx).

\subsubsection{Ownership and Access}

Who owns research data? (http://ori.hhs.gov/education/products/n_illinois_u/datamanagement/dotopic.html; http://ori.hhs.gov/education/products/n_illinois_u/datamanagement/dotopic.html).
The scientific community lacks consensus on the answer, and the developmental science community is no exception.
Federal funding agencies might argue that the public should `own' data paid for by tax dollars, much like other data collected by government agencies like the U.S. Census, National Weather Service, and U.S. Bureau of Labor Statistics.
The institutions that employ, receive, and manage federal grants might stake a claim to ownership.
Most investigators naturally feel a strong sense of ownership over their intellectual products, even though formal copyright is often surrendered in the process of publishing, and that sense extends to data.
Some have even argued that research participants themselves own their own data, and there are new business models emerging that may soon provide individuals an opportunity to sell data for personal gain (http://www.datawallet.io).

The lack of consensus about who owns data means that access is often limited in ways that impede reuse by others.
Some investigative teams control who has access to datasets, for what purposes and for how long.
That control may persist indefinitely.
Others grant access to data only if co-authorship on any published product is guaranteed.
While legimate arguments might be made in favor of `embargo' periods that enable teams of researchers to mine and report findings from their research efforts, the ideal of fostering greater data reuse argues for shorter periods.
Establishing consensus about data ownership and the kind of control investigators can exercise over it will require conversations among researchers, institutions, and funding agencies.
That consensus may well prove vital to achieving some of the benefits of big data analyses in development. 

\subsubsection{Challenges of conducting big data developmental research}

The increasing availability of big datasets for analysis in developmental research poses significant theoretical and conceptual questions alongside the many pragmatic ones already discussed.
Big(ger) data may help to overcome limitations with our existing knowledge base.
One challenge that big data may help to address is a particular bias in existing samples.
Developmental research presumes to study what is normative about changes across time in human behavior.
But, much of what behavioral and social science has learned about developmental processes comes from samples that represent only a small fraction of the world's population.
Developmental psychology, like other branches of the field, presents findings from Western, education, industrialized, rich, and democratic (WEIRD) societies (http://www.theatlantic.com/daily-dish/archive/2010/10/western-educated-industrialized-rich-and-democratic/181667/).
So, to the extent that new tools enable research on development in non-WEIRD cultures and those data can be aggregated and combined, the extent to which developmental science can make claims about universal or near-universal components of developmental processes will be strengthened.
On the other hand, developmental researchers are well aware of cohort effects -- the notion that developmental processes highly influenced by changing social and cultural norms are themselves subject to change.
Thus, even the most culturally diverse dataset possible may still yield conclusions that are `locked' in time.

A second challenge larger datasets may help to address is the fact that most social, behavioral \cite{Maxwell-2004} and neuroscience studies \cite{Button-NRN} are underpowered.
Most worryingly it has been claimed that most published research findings are false in fields with specific characteristics: Sample or sizes are small; more relationships between variables are tested; preselection of tested relationships is less common and exploratory research more common; designs, definitions, outcomes, and analytical modes are less consistent across studies; and when more teams are involved seeking out significant effects \cite{Ioanidis}.
The collection, analysis, and sharing of larger size datasets may help to ameliorate some, but not all, of these flaws.

Developmental research faces a specific point of tension related to the measurement.
Many of the measures for which high volume data are available come from proprietary, expensive to license instruments like the Bayley, WIPPSI.
Where free, academic instruments are in use like the Infant Behavior Questionnaire, there remains no centralized archive for those data.
Plus, the measures themselves have been revised several times, making it more challenging to compare data collected using different versions, especially across time.
Similar problems arise when non-proprietary tasks are used.
Most investigators customize even a well-known task to make it suitable for use with children, and the sharing of research materials is not substantially more widespread than the sharing of data.
Efforts to encourage researchers to capture and record the conceptual structure of psychological tasks have been undertaking (e.g., The Cognitive Atlas), but they have not been widely adopted even by the target community of researchers in adult cognitive neuroscience.

Finally, some have raised concerns that the rise of especially large datasets means the `end of theory.' \cite{Anderson}
In a provocative essay in 2008, Anderson argued that large quantities of data mean the traditional model of scientific inquiry involving hypothesis testing will soon give way to model-free descriptions of data.
Others note that bigger data don't necessarily lead to deeper insights \cite{Graham} (http://www.theguardian.com/news/datablog/2012/mar/09/big-data-theory).
Boyd and Crawford note \cite{boyd} that beyond its scientific dimensions, `big data' is a sociocultural phenomenon that raises as many questions as it promises answers.

\section{Conclusion}

As boyd and Crawford note, `The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions.' \cite{boyd}
The clamor extends to the developmental and learning sciences where interests in understanding how to maximize the potential for human achievement and improve health have significant consequences for daily living.

This review has shown that the collection, dissemination and analysis of data sets that are big in volume, velocity, or variety has a long and established history in developmental science.
Many `big data' studies have had substantial impact on scholarship, as measured by the quantity of published findings, and in some cases, on public understanding and policy.

Research and data management practices have begun to converge on norms that will reduce the costs of preparing data for sharing.
New ethical procedures
New data archives, increasing support for sharing, both bottom-up and top down.

Data are still hard to access, even for researchers.
Most data are not in repositories, file drawer effect.
Most data not prepared or curated for sharing.
Data hard to understand without help of original investigators.
No widespread culture of data sharing except in specific subfields, CHIDLES.
No unified understanding/cultural consensus about who owns data, when to share, etc.

At the same time, while scientific culture may appear to change slowly, let us remember that the Facebook website was launched in 2004, Twitter in 2006.
It would be unwise to underestimate the speed with which new technologies and tools can change our lives.
If developmental researchers can find ways to collect, manage, store, share, and enable others to reuse data about the multiple facets of human development, we can look forward to a future rich in theory and understanding.

\bibliography{big-data}

\end{document}