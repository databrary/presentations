\documentclass{sig-alternate}

\begin{document}
\conferenceinfo{JCDL}{'15 Knoxville, Tennesse USA}

\title{Databrary: A digital data library for sharing research video}

\numberofauthors{3}

\author{
\alignauthor
Dylan A. Simon\\
	\affaddr{Databrary Project}\\
	\affaddr{New York University}\\
	\affaddr{New York, NY, USA}\\
	\email{dylan@databrary.org}
\alignauthor
Drew Gordon\\
	\affaddr{Databrary Project}\\
	\affaddr{New York University}\\
	\affaddr{New York, NY, USA}\\
	\email{drew@databrary.org}
\alignauthor
Rick O. Gilmore\\
	\affaddr{The Pennsylvania State University}\\
	\affaddr{Department of Psychology}\\
	\affaddr{University Park, PA, USA}\\
	\email{rogilmore@psu.edu}
}

\maketitle

\begin{abstract}
%%dg being that the conference them is big data, should we be trying to be more explicit about that?
% big data is generally referring to "more rows" rather than larger files. I think the closest we get is the size of video files
% which is already noted below. Just wondering if it makes sense to be more explicit or not.
%%dg also preservation and discoverability - though maybe that's included in data management
%%rg video is big/dense in time and space. But, much of the size is masked without intensive analysis by humans or machines. Compare it with brain imaging data. A typical brain imaging study might include 3-5 runs of 200 brain volumes with 30 128x128 pixel x 8 bit greyscale slices per volume, with each volume collected about every 2-3 sec (.33-.5 Hz). Video is much "bigger" because it samples space and time densely.
\end{abstract}

\category{H.2.8}{Database Management}{Database Applications}[scientific databases, image databases]
\category{H.3.5}{Information Storage and Retrieval}{Online Information Systems}[data sharing, web-based services]

\terms{Design, Standardization}

\keywords{Data sharing, open science, video, psychology, developmental science}

\section{Introduction}

%rog The text you removed explained how and why video is actually "data." Maybe that's not important for this audience. What are the questions we are trying to answer with this paper? I'd argue for the following: 1) Why video? 2) What challenges does video pose? 3) How does Databrary solve these challenges? 4) What challenges remain unmet? 5) What lessons does Databrary offer other data repositories?

Video and audio recordings play a key role in many areas of research, especially in psychology, linguistics, education, ethnography, and ethology.
Video documents experimental procedures or behaviors, conveys ideas, provides examples for teaching and scientific communication, and serves as a rich primary data source for later analysis.
Unfortunately, in standard practice, the use of video data is restricted to the researchers who collect them, due largely to the perceived requirements around privacy restrictions.
The goal of the Databrary project is to create tools that allow video data to be documented, organized, and shared so that other researchers can discover and re-purpose them for their own research interests.
Accordingly, Databrary, with an initial focus on research in developmental psychology and related fields, has created a web-based library to accommodate the storage and organization of video data, capture contextual information necessary for re-use, and standardize across datasets without placing undue burden on data contributors.
In this paper, we discuss the design and technical challenges of the system and describe some findings and structural solutions to these challenges. The larger discussion involving research data repositories and the role of libraries in automating and facilitating access to research data well after its original use is very much active and ongoing \cite{Castelli_etal_2013, Nielson_Hj√∏rland_2014, Macmillan_2014}. While Databrary is a model for tackling some of the challenges there, the scope of this paper focuses more on how we handle research data of a specific format and from a specific discipline, with implications for the future of data cataloging and reuse in other contexts.

We have intentionally chosen to focus our efforts on hosting human-consumable, self-documenting, timeseries data: video and audio recordings.
Though while these types of data are an accessible and potent source for research analysis, they also present additional challenges \cite{Lanagan_Smeaton_2012}.
On one hand, recordings can be and largely are consumed and analyzed, at least initially, without sophisticated tools: once digitally decoded, trained human observers can glean directly much of the data's richness.
In particular, video data collected in one context can often be used by others for different purposes with minimal explanation, as the nature of the subjects and activity are readily apparent.
This naturally reduces the problems of documentation and re-use that plague most flat-file or dense datasets.
On the other hand, since automated analysis of videos is an active yet immature research area, the problems of search, discoverability, and meta-analysis over these media remain \cite{Albertson_2013}.
We attempt to address these issues by augmenting the primary recording data with additional structured and unstructured features.

%\section{Normalization vs. Flexibility}

We have found in researching existing research data repositories that there are two competing approaches that need to be balanced out.
On the one hand, a system might tend towards more generality, providing unstructured storage of arbitrary files.
On the other, it can present a rigorously structured schema that requires contributors to properly extract and format contributions in a highly specified manner.
While the former is well suited for archival of entire datasets and general-purpose hosting of resources, it does not facilitate detailed search, understanding, or re-use across various datasets without a great deal of curation \cite{Peer_2012}.
The latter, on the other hand, generate large-scale, homogeneous data sources for meta- and re-analysis, but are limited to specific domains and research questions, losing the full richness, context, and innovation of the source materials and field.
We have attempted to strike a balance between these extremes by focusing on video and audio recordings as the unifying factor and allowing additional resources to be built and discovered around this core.

Databrary can incorporate heterogeneous datasets within our target domain by allowing secondary, general-purpose flat-file data, materials, and references to be associated with the primary data.
This facilitates storage and retrieval of data more closely mapped to the original context in which it was collected and analyzed.
At the same time, it provides a common, standard structure for recordings and their associated metadata, including context, contents, and annotations.
We achieve this conformance of datasets in the library through a combination of in-depth investigative curation and ingest processes for already-collected data, and a well-defined user experience that provides a platform for researchers to contribute and organize all of their research data as they are collected.
The following section provides specific detail on the design and decision-making behind this unifying structure.

\section{Data Architecture}

%%dg would a figure illustration be helpful here? do we already have one?

As with most user-driven databases, we separate individual data contributions into collections or packages variously referred to as datasets, studies, or volumes.
Volumes can be associated with a minimal amount of metadata (title, description, permissions, etc.) as well as additional files (documents and other materials).
These volumes are to some extent embeddable and referenceable, both among themselves and to and from external entities by DOI or URI.
The remainder of this work will address the available structures for data within these volumes, highlighting how these structures allow commonalities between volumes to be represented.

There are two key, innovative structural elements that comprise a volume: the session and the record.
Sessions are the primary container for data files, basically an elaboration on traditional file folders with additional temporal metadata.
Records are used to represent all types of scalar variable-based data, traditionally contained in flat files or databases, as well as to provide an organizational structure among sessions.
The combination of these two elements allows data and metadata to be flexibly related and annotated.

\subsection{The ``Session''}

Researchers record activities with individuals either for the purpose of a later, closer review or analysis, or simply to document and verify measurements and observations made during the collection \cite{Bakeman_2012}.
Thus, the recording itself is often the core item of research, representing a single data collection, experiment, trial, visit, or case depending on the nature of the research.
However, in many cases a single session can comprise multiple videos: from serial data streams due to recording equipment producing multiple files, and/or in parallel from multiple data capture sources operating at the same time.
These primary recordings may also be augmented with other forms of timeseries data such as motion capture, eye tracking, or physiological recordings, as well as with additional point-in-time measurements, observations, or surveys, all of which have specific and critical temporal relationships with the primary data. 

When working with multiple primary recordings, researchers often reduce these raw files into a single representation.
For example, they may concatenate serial recordings or make a composite video by joining or overlaying frames.
Secondary data is also often overlaid or combined in this way, such as by adding an additional waveform or frequency visualization below a video, or by overlaying cross-hairs representing location or gaze data.
Doing so allows for more convenient human analysis of the data in standard playback tools that only support a single data stream, but also loses some of the raw data, by obscuring, masking, or downsampling spatially or temporally.
The session was thus designed to organize data in a way that is familiar to researchers without requiring these modifications. By also supporting the upload of multiple video files for a session, Databrary provides a workflow for their research in progress and not merely as a final resting place.
%dg-I am not married to the above sentence.   

A session object captures these relationships to represent a single data acquisition, comprising not only arbitrary files but also their absolute or relative temporal positioning.
The metaphor we use here is a timeline <good place for a screenshot> , wherein each session defines a time range, with absolute timestamps representing the exact time of data collection, or relative positioning defined by a 0 starting point of the collection (or potentially any other meaningful wall-time units) with an optional date.
Files placed within a session can then be (optionally) positioned, much as in video or audio editing software.
Although some advanced recording equipment provides automatic timestamping or synchronization than can be used, most researchers collecting multiple parallel data streams use ``sync points'' such as an electronic trigger signal, flash, or tone to align recordings.
These sync points can then be used to manually place recordings on the timeline appropriately.

\subsubsection*{Simple annotations}

Once the timeframe of a session is established, this allows temporally-positioned annotations to be attached to the session. Currently these annotations take the form of keyword-based tagging and comment-based discussions on any temporal segment of a session supplied manually by users. In future releases we expect to support annotations created by automated video analyis systems.

This practice of annotation is very common in research when analyzing recordings, and specialized desktop software tools are employed to review video and audio to annotate events, utterances, actions, or scenes at any temporal scale, from individual samples/frames to the entire session.
Most of these tools currently focus on a single recording file, however, and despite the plethora of tools and features, there is little interoperability. By supporting this annotation of positioned segments in a session, researchers can not only organize their data, and see it in ways familiar to their research, but also create additional metadata, and thus value of the dataset for other users, on top of it. 

In addition to enriching datasets for the creators of the data, these annotations will also provide an index target for additional discovery capabilities for users looking for particular features within data.

\subsection{The ``Record''}

An object called a record serves a number of purposes around session and metadata organization. 
A record itself represents any number of variables or measurements---what would traditionally be a row of a database or flat file. Defining this component broadly supports the flexibility of the system, while giving this data a discrete place in the data schema.
For example, a record may represent an individual participant within the dataset and contain their subject identifier, gender, birth date, and any other demographic, survey, or measurement data about that individual.
A record could also represent a particular experimental task, condition, location, or outcome, and contain variables with corresponding parameters or descriptions.
Records are thus labeled and divided by the type of entity they represent.
The variables themselves are textual, numeric, date, or potentially any other scalar data as in any traditional tabular data interface, with the records of a given type then constituting the tabular rows.

Records are also used to organize sessions.
We observed that different researchers organize their data files in different ways according to the type of research.
Many consider participants to be the primary item of analysis, and so create a directory for each participant.
Others organize their data based on date, experimental condition, phase of analysis, or age groups.
Sometimes even single video files are split up into segments according to scene or activity, and researchers consider this property the primary organizational principal.

Rather than trying to handle all of these strategies separately, we instead leverage records.
That is, records can be attached to sessions, or, equivalently, sessions can be grouped into records, in a many-to-many relationship.
For example, in a traditional psychology study, each participant may appear in exactly one session, so the collected information about that participant, added to the record, is attached one-to-one with their session.
A dataset may also be composed of a few different sub-sets based on experimental procedures or location, and here each session would be placed into exactly one of these few records.
In some research, multiple participants may also appear in multiple sessions, such as recordings of the same class of students over a span of time.

Since researchers can create whichever record types apply to their data, they can then choose to group their data by whichever record type they wish.
This also allows users to either import or export data in what they consider the native directory structure by indicating the appropriate nesting of record types.
By providing some standardization of record types, we can also perform broad, meta-searches across the library, for example for all videos containing participants of a particular age range.

\subsubsection*{Structured annotations}

Finally, records can be attached not only to entire sessions, but also to arbitrary temporal sub-sets of a session.
That is, if any record only applies to part of a session, for example a single activity, or a participant being present for only part of a recording, it can be applied within the timeline of a session to only the appropriate part.
This allows the final type of organizational structure, wherein records define virtual sub-sessions that can be grouped and interacted with as units, without needing to cut up source videos.
It also can be used to represent annotations at a finer temporal scale, for example individual events interactions that are normally handled by off-line annotation software.
However, the appropriate interfaces and tools to input or import these annotations are still being developed.

\subsection{Technical infrastructure}

Databrary is a new, cohesive web application, built on the Play Framework to enable a responsive user interface, a complete API, and high-performance streaming.
Recordings and other files are placed in content-based filesystem storage, and all structured data are stored in a PostgreSQL database, leveraging its geometric indexing capabilities for temporal data.
All uploaded recordings are automatically transcoded to a standard format to enable cross-platform HTML5-based streaming and downloading for off-line access, currently H.264/AAC in an MPEG-4 container for video.
This transcoding utilizes the high performance computing cluster at the hosting campus of New York University, using ffmpeg's libav bindings for both this and direct access to video frames and clips.
The user interface is built primarily on the Angular web framework, and all data access is performed through an open JSON API.
Although hosted data are protected, all source code is released under a GPLv3 license on github.

\section{Normalization vs. Flexibility}

As the extant research data libraries demonstrate, there is always the tension between normalization and flexibility.
Since we're primarily dealing with video and audio data, standardizing on an encoding format allows for convenient, consistent access without much loss of flexibility, while still allowing arbitrary resolutions, encoding qualities, and sample/frame-rates.
We also allow for ``dumps'', which allow users---using certain portable formats (flat-files, documents, images, data)---to include any data that cannot be encompassed by our standard formats.
In this way, we can incorporate data which may be relevant for re-use but not broadly adopted by the community, without making the system too rigid.

Here we have also introduced a number of metadata concepts where this tension becomes most apparent, namely the available record types, variables (and values within categorical data types), and tag keywords.
We have adopted an approach of encouraging adherence to existing standardized options but also allowing new types to be created as the data require it.
Initially we have achieved this through manual review and off-line curation of contributions, dynamically extending the system as new types of data were discovered.
For many previously collected datasets, this has proven the most effective method to both learn from data and avoid burdening contributors.
However, since we expect the bulk of the data in the library to come from newly collected sources (due largely to privacy constraints on existing datasets), we have additionally taken a separate, user-driven approach.

We found that while some researchers in our target domains have standardized data management practices, a large majority have no special data management or collection tools, often using a combination of hand-written paper, simple spreadsheets, existing video annotation tools, statistical analysis software, and available filesystem storage (often just external hard-drives).
This suggested the opportunity to supply a cohesive data management platform where all collected raw data, including recordings, contextual information, and measurements, could be entered, stored, and exported for later off-line analysis.
Providing a targeted user interface to meet the existing and evolving needs of our contributed data allows us to control the means of data entry and thus achieve a greater amount of normalization in the data from the outset through liberal use of auto-completion, suggestions, and drop-down options.
With the considerable benefit of reducing storage requirements within researcher's labs, and often adding convenience over existing practices, this has proven an attractive prospect for researchers.

Achieving the appropriate balance will no doubt be challenging, but by using the above approaches and limiting our focus to particular research domains we have been able to achieve a good amount of standardization across the entire data library without overly burdening contributors.

\section{Implications for Digital Libraries}
%%dg this might or might not be valuable but I am wondering if this is a section that might help draw all the pieces together.

\section{Ongoing Challenges and Next Steps}
  
 1) Improving the API for interoperability with other systems
 2) Metadata interoperability: DOIs; Export in friendly formats (Dublin Core, METS), OAI-PMH compliance.
 3) ...

\section{Conclusions}

\section*{Acknowledgments}

This work was supported by the National Science Foundation (BCS-1238599) and the National Institute of Child Health and Human Development (U01-HD-076595-01).
The authors gratefully acknowledge the NYU Libraries for their valuable advice and consultation.

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}
