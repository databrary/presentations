\documentclass{sig-alternate}

\begin{document}
\conferenceinfo{JCDL}{'15 Knoxville, Tennesse USA}

\title{Databrary: A digital data library for sharing research video}

\numberofauthors{3}

\author{
\alignauthor
Dylan A. Simon\\
	\affaddr{Databrary Project}\\
	\affaddr{New York University}\\
	\affaddr{New York, NY, USA}\\
	\email{dylan@databrary.org}
\alignauthor
Drew Gordon\\
	\affaddr{Databrary Project}\\
	\affaddr{New York University}\\
	\affaddr{New York, NY, USA}\\
	\email{drew@databrary.org}
\alignauthor
Rick O. Gilmore\\
	\affaddr{The Pennsylvania State University}\\
	\affaddr{Department of Psychology}\\
	\affaddr{University Park, PA, USA}\\
	\email{rogilmore@psu.edu}
}

\maketitle

\begin{abstract}
%%dg being that the conference them is big data, should we be trying to be more explicit about that?
% big data is generally referring to "more rows" rather than larger files. I think the closest we get is the size of video files
% which is already noted below. Just wondering if it makes sense to be more explicit or not.
%%dg also preservation and discoverability - though maybe that's included in data management
%%rg video is big/dense in time and space. But, much of the size is masked without intensive analysis by humans or machines. Compare it with brain imaging data. A typical brain imaging study might include 3-5 runs of 200 brain volumes with 30 128x128 pixel x 8 bit greyscale slices per volume, with each volume collected about every 2-3 sec (.33-.5 Hz). Video is much "bigger" because it samples space and time densely.
\end{abstract}

\category{H.2.8}{Database Management}{Database Applications}[scientific databases, image databases]
\category{H.3.5}{Information Storage and Retrieval}{Online Information Systems}[data sharing, web-based services]

\terms{Design, Standardization}

\keywords{Data sharing, open science, video, psychology, developmental science}

\section{Introduction}

Video and audio recordings play a key role in many areas of research, especially in psychology, linguistics, education, ethnography, and ethology.
Video documents experimental procedures or behaviors, conveys ideas, provides examples for teaching and scientific communication, and serves as a rich primary data source for later analysis.
Unfortunately, in standard practice, the use of video data is restricted to the researchers who collect them, due largely to the perceived requirements around privacy restrictions.
The goal of the Databrary project is to create tools that allow video data to be documented, organized, and shared so that other researchers can discover and re-purpose them for their own research interests.
Accordingly, Databrary, with an initial target audience of developmental psychology and related fields, has created a web-based library to accommodate the storage and organization of video data, capture contextual information necessary for re-use, and standardize across datasets without placing undue burden on data contributors.
In this paper, we discuss the design and technical challenges of the system and describe some findings and structural solutions to these challenges.

Existing research data repositories present two competing approaches that need to be balanced out.
A system might tend towards more generality, providing unstructured storage of arbitrary files.
Alternatively, it can present a rigorously structured schema that requires contributors to format contributions in a highly specific manner.
While general-purpose repositories are well-suited for archival of entire datasets and flexible hosting of resources, they do not facilitate detailed search, understanding, or re-use across various datasets without a great deal of curation \cite{Peer_2012}.
Targeted repositories, on the other hand, generate large-scale, homogeneous data sources for meta- and re-analysis, but are limited to specific domains and research questions, losing the full richness, context, and innovation of the source materials and field.
We have attempted to strike a balance between these extremes by focusing on video and audio recordings as the unifying factor and allowing additional structured and unstructured resources to be built and discovered around this core.

\subsection{Video-driven research}

We have intentionally chosen to focus Databrary on hosting human-consumable, self-documenting, timeseries data: video and audio recordings.
While these types of data are an accessible source for research analysis, they also present additional challenges \cite{Lanagan_Smeaton_2012}.
Recordings can be and largely are consumed and analyzed, at least initially, without sophisticated tools: once digitally decoded, trained human observers can directly glean much of the data's richness.
In particular, video data collected in one context can often be used by others for different purposes with minimal explanation, as the nature of the subjects and activity are readily apparent.
This naturally reduces the problems of documentation and re-use that plague most flat-file datasets. % wanted to include raw, opaque data here, too
However, since automated analysis of videos is an active yet still immature research area, the problems of search, discoverability, and meta-analysis over these media remain \cite{Albertson_2013}.

Research using recordings of these types typically proceeds by annotating or scoring raw data.
In order to extract value from recordings for further analysis, researchers add temporally-positioned annotations, either by direct observation or with the aid of simple visualizations or analysis tools.
Myriad specialized desktop software tools are employed to review video and audio to annotate events, measurements, utterances, or behaviors at any temporal scale, from individual samples/frames to the entire session.
Most of these tools currently focus on a single recording file, and despite the plethora of tools and features, there is little interoperability.
Moreover, there is almost no standardization of these annotations themselves, even across studies performed by the same researcher \cite{?}.

\subsection{Approach}

Databrary's approach to data is to provide as much context around the primary recordings as possible while still providing contributors some flexibility.
To keep datasets intact, Databrary can incorporate heterogeneous datasets within our target domain by allowing secondary, general-purpose flat-file data, materials, and references to be associated with the primary data.
This facilitates storage and retrieval of data more closely mapped to the original context in which it was collected and analyzed.
At the same time, it provides a common, standard structure for recordings and their associated metadata, including context, contents, and annotations.
We achieve this conformance for previously collected datasets through a combination of in-depth investigative curation and automated, server-side ingest processes.
For datasets that are in the process of being collected, a well-defined user experience provides a platform for researchers to contribute and organize all of their research data as they proceed with their study.
The following section provides specific detail on the design and decision-making behind this unifying structure.

\section{Data Architecture}

%%dg would a figure illustration be helpful here? do we already have one?

At the top level of organization, we separate individual data contributions into collections or packages variously referred to as datasets, studies, or volumes.
Volumes can be associated with a minimal amount of metadata (title, description, permissions, etc.) as well as additional files (documents and other materials).
These volumes are to some extent embeddable and referenceable, both among themselves and to and from external entities by DOI or URI.
%%dg can we expand on the above sentence, what does this mean and what are the implications?
The remainder of this work will address the available structures for data within these volumes, highlighting how these structures allow commonalities between volumes to be represented.

There are two key, innovative structural elements that comprise a volume: the \emph{session} and the \emph{record}.
Sessions are the primary container for data files, an elaboration on traditional file folders with additional temporal metadata.
Records are used to represent all types of scalar variable-based data, traditionally contained in flat files or databases, as well as to provide an organizational structure among sessions.
The combination of these two elements allows data and metadata to be flexibly related and annotated.

\subsection{Sessions}

The session in Databrary draws from accepted and documented practices around how researchers record activities with individuals.
Recordings are made either for the purpose of a later, closer review or analysis, or simply to document and verify measurements and observations made during the collection \cite{Bakeman_2012}.
Thus, the recording itself is often the core item of research, representing a single data collection, experiment, trial, visit, or case depending on the nature of the research.
However, in many cases a single session can comprise multiple videos: from serial data streams due to recording equipment producing multiple files, and/or in parallel from multiple data capture sources operating at the same time.
These primary recordings may also be augmented with other forms of timeseries data such as motion capture, eye tracking, or physiological recordings, as well as with additional point-in-time measurements, observations, or surveys, all of which have specific and critical temporal relationships with the primary data.

When working with multiple primary recordings, researchers often combine these raw files into a single representation.
For example, they may concatenate serial recordings or make a composite video by joining or overlaying frames.
Secondary data is also often overlaid or combined in this way, such as by adding an additional waveform or frequency visualization below a video, or by overlaying cross-hairs representing location or gaze data.
Doing so allows for more convenient human analysis of the data in standard playback tools that only support a single data stream, but also loses some of the raw data, by obscuring, masking, or downsampling spatially or temporally.
The session was thus designed to organize original recordings in a way that is familiar to researchers, keeping their data in the rawest and most flexible form without requiring these modifications.
This additionally allows for greater options in reuse by other researchers.

A session object captures these relationships to represent a single data acquisition, comprising not only arbitrary files but also their absolute or relative temporal positioning.
The metaphor we use here is a timeline, wherein each session defines a time range, with absolute timestamps representing the exact time of data collection, or relative positioning defined by a 0 starting point of the collection (or potentially any other meaningful wall-time units) with an optional date.
% good place for a screenshot?
Files placed within a session can then be (optionally) positioned, much as in video or audio editing software.
Although some advanced recording equipment provides automatic timestamping or synchronization than can be used, most researchers collecting multiple parallel data streams use ``sync points'' such as an electronic trigger signal, flash, or tone to align recordings.
These sync points can then be used to manually place recordings on the timeline appropriately.

\subsection{Records}

An object called a record serves a number of purposes around session and metadata organization.
A record itself represents any number of variables or measurements: what would traditionally be a row of a database or flat file.
Records can thus represent most any item of analysis or organization typically represented in this form.
For example, a record may represent an individual participant within the dataset and contain their subject identifier, gender, birth date, and any other demographic, survey, or measurement data about that individual.
A record could also represent a particular experimental trial, task, condition, location, or outcome, and contain variables with corresponding measurements, parameters, descriptions.
Records are thus labeled and divided by the type of entity they represent.
The variables themselves are textual, numeric, date, or potentially any other scalar data as in any traditional tabular data interface, with the records of a given type then constituting the tabular rows.

Records are also used to organize sessions.
We observed that different researchers organize their data files in different ways according to the type of research.
Many consider participants to be the primary item of analysis, and so create a filesystem directory for each participant.
Others organize their data based on date, experimental condition, phase of analysis, or age groups.
Sometimes even single video files are split up into segments according to scene or activity, and researchers consider this property the primary organizational principal.

Rather than trying to handle all of these strategies separately, we instead leverage records.
That is, records can be attached to sessions, or, equivalently, sessions can be grouped into records, in a many-to-many relationship.
For example, in a traditional psychology study, each participant may appear in exactly one session, so the collected information about that participant, added to the record, is attached one-to-one with their session.
A dataset may also be composed of a few different sub-sets based on experimental procedures or location, and here each session would be placed into exactly one of these few records.
In some research, multiple participants may also appear in multiple sessions, such as recordings of the same class of students over a span of time.

Since researchers can create whichever record types apply to their data, they can then choose to group their data by whichever record type they wish.
This also allows users to either import or export data in what they consider the native directory structure by indicating the appropriate nesting of record types, along with the record variables themselves in traditional CSV formats.
By providing some standardization of record types, we can also perform broad, meta-searches across the library, for example for all videos containing participants within a particular age range.

\subsection{Annotations}

Establishing a timeline for each session allows temporally-positioned annotations to be attached to the session.
Currently we support two types of annotations: structured, organizational annotations based on records and added by the data contributors; and simple annotations contributed by the community.
Eventually we hope to extend both of these to support the full range of annotations performed during analysis, both directly on the web and imported from existing software.

First, records can be attached not only to entire sessions, but also to arbitrary temporal sub-sets of a session.
If any record relates to a part, scene, or section of a session---for example a participant being present for only part of a recording---it can be applied within the timeline of a session to only that appropriate part.
This allows an additional type of organizational structure researchers employ, wherein records define virtual sub-sessions that can be grouped and interacted with as units, without needing to cut up source videos.
This can also theoretically be used to represent annotations at a finer temporal scale, for example individual trials or events that are normally handled by off-line annotation software.
However, the appropriate interfaces and tools to input or import these annotations are still being developed.

Second, we support simple keyword-based tagging and comment-based discussions on any temporal segment of a session.
Such annotations can also be added through our API by automated video analysis according to features of interest identified in the data.
In addition to enriching datasets and enabling dialog between researchers, we expect these annotations to provide an index target for additional discovery capabilities for users looking for particular features within data \cite{Lanagan_Smeaton_2012}.

\subsection{Technical infrastructure}

Databrary is a new, cohesive web application, built in Scala on the Play Framework\footnote{http://playframework.com/} to enable a responsive user interface, a complete API, and high-performance streaming.
Recordings and other files are placed in content-based filesystem storage, and all structured data are stored in a PostgreSQL database, leveraging its geometric indexing capabilities for temporal data.
All uploaded recordings are automatically transcoded to a standard format to enable cross-platform HTML5-based streaming and downloading for off-line access, currently H.264/AAC in an MPEG-4 container for video.
This transcoding utilizes the high performance computing cluster at the hosting campus of New York University, using ffmpeg's libav bindings for both this and direct access to video frames and clips.
The user interface is built primarily on the Angular web framework\footnote{http://angularjs.org/}, and all data access is performed through an open JSON API.
Although hosted data are protected, all source code is released under a GPLv3 license on github\footnote{http://github.com/databrary}.

\section{Repository}

The Databrary website was opened for general use in October 2014 and has accepted contributions since earlier that year.
It currently hosts 5700 video files totaling 1600 hours of recordings along with 2200 additional files.
These files comprise 2400 sessions and are covered by 1300 records (including 1100 individual participants).
Data originates from 35 individual contributors across 25 different universities.

\subsection{Normalization}

As the extant research data libraries demonstrate, there is always the tension between normalization and flexibility.
Since we primarily deal with video and audio data, standardizing on an encoding format allows for convenient, consistent access without much loss of flexibility, while still allowing arbitrary resolutions, encoding qualities, and sample/frame-rates.
We also allow allow users, using certain portable formats (flat-files, documents, images), to include any data that cannot be encompassed by our standard formats.
In this way, we can incorporate data which may be relevant for re-use but not broadly adopted by the community, without making the system too rigid.

Here we have also introduced a number of metadata concepts where this tension becomes most apparent, namely the available record types, variables (and values within categorical data types), and tag keywords.
We have adopted an approach of encouraging adherence to existing standardized options but also allowing new types to be created as the data require it.
Initially we have achieved this through manual review and off-line curation of contributions, dynamically extending the system as new types of data were discovered.
For many previously collected datasets, this has proven the most effective method to both learn from data and avoid burdening contributors.
However, since we expect the bulk of the data in the library to come from newly collected sources (due largely to privacy constraints on existing datasets), we have additionally taken a distinct, user-driven approach.

We found that while some researchers in our target domains have standardized data management practices, a large majority have no special data management or collection tools, often using a combination of hand-written paper, simple spreadsheets, existing video annotation tools, statistical analysis software, and available filesystem storage (often just external hard-drives).
This suggested the opportunity to supply a cohesive data management platform where all collected raw data, including recordings, contextual information, and measurements, could be entered, stored, and exported for later off-line analysis.
Providing a targeted user interface to meet the existing and evolving needs of our contributed data allows us to control the means of data entry and thus achieve a greater amount of normalization in the data from the outset through liberal use of auto-completion, suggestions, and drop-down options.
With the considerable benefit of reducing storage requirements within researcher's labs, and often adding convenience over existing practices, this has proven an attractive prospect for researchers.

Achieving a sustainable balance will no doubt be challenging, but by using the above approaches and limiting our focus to particular research domains we have been able to achieve a good amount of standardization across the entire data library without overly burdening contributors.

\subsection{Discovery}

While increased normalization facilitates filtering and targeted searches for data, the general problems of browsing and discovery remain largely unsolved.
This problem is compounded for us because we expect researchers not only to reuse and reanalyze data within their own research area, but potentially to find new uses data originally collected for entirely different purposes.
Recordings with potential value in one research area may be primarily labeled with contextual information from a different research area.
Ultimately, making this determination requires direct, human observation of the recordings, and so a large part of solving the discovery problem will be simply to present researchers with short, representative samples from a variety of datasets.

Another important source for search targets would come from annotations supplied both by the original researchers during analysis as well as by the community.
In the former case, normalization remains a concern, as most annotation schemes researchers employ involve opaque, symbolic or numeric codes with little semantic content.
We are currently working to support import and export workflows for existing annotations tools that will be able to add meaningful definitions to these codes while researchers continue their current practices.
Beyond that, we also plan to build a new, more efficient and structured annotation web interface enabling more of the analysis workflow directly within our system
In this way, Databrary will allow researchers to work with their recordings directly in raw form without having to transfer or transform them, while also capturing more meaningful and standardized contextual information from this process.

\section{Conclusions}

Starting from the perspective of a general-purpose repository, we have introduced a number of significant restrictions to create a specialized, domain repository for specific types of data.
By limiting both file and metadata organization to a flat (but overlapping) set of sessions and records, rather than supporting the full hierarchical richness of other systems, we can present and capture session-based research data with a cohesive and intuitive user interface.
By focusing on video and audio recordings we can normalize presentation and discovery of data across the site, and also introduce temporal structure to data and annotations driven by the nature of these recordings.
Although we allow a few types of additional data files, we encourage users with other types of rich data, such as physiological recordings, to store and link to those resources externally, ideally in similarly focused and better-suited repositories.
Similarly, by targeting use cases around finding new uses for existing research data, rather than replication or meta-analysis, we can limit the scope of accepted data to the original recordings and early analysis phases that generate the most value, rather than trying to capture the entire provenance.

Having made significant progress building ingest and data entry services that have let us grow the library, we now must turn our efforts towards discovery and reuse, finding ways to better describe and elaborate on collected data.
To do this we look both to the original data contributors for ways that their existing analysis workflows can generate usable content descriptions, and to the community of researchers to label and comment on datasets as they explore.
Thus we seek to incorporate these existing annotation processes into Databrary, both to capture and define these annotations as generalizable search terms, and to make these workflows more convenient by obviating existing file transfer and transformation burdens.
Ultimately we hope to allow and capture instances of data reuse in this same way, so that content descriptions are aggregated from multiple annotation passes from different users and existing data can continuously increase in value for researchers.

There is also active discussion around the role of repositories and libraries in archiving and providing access to research data, where the roles and responsibilities between libraries and research departments is not entirely established \cite{Castelli_etal_2013, Nielson_Hj√∏rland_2014, Macmillan_2014, Pinfield_etal_2014}.
Although resolving this complicated issue is not directly within our purview, we have laid out a functioning system for research data management that may bring data closer established library standards that achieve these goals.
We may be well positioned to provide interoperability with library-based metadata schemas (such as export of data packages cross-walked to Dublin Core or METS schemas) and reach OAI-PMH compliance, so as to automatically incorporate the data that researchers add to Databrary into federated library searches with other domain specific data repositories.
By providing a refined API and assigning Digital Object Identifiers (DOIs) to volumes, we can also allow libraries and other information systems to tap into Databrary datasets.

% this is kinda weird, but maybe suitable for a last paragraph?
Our single-minded focus on making collected, identifiable recordings of human research available and reusable to a whole community of researchers gives us a novel perspective on building domain-specific research repositories.
The success we've had in engaging, involving, and extracting data from researchers is due largely to this focus, but it has come at the cost of limitations in scope and difficulties of interoperability and discovery that many more traditional repositories avoid.
By slowly growing our scope and relaxing some of these limitations, we hope to leverage more of the established knowledge of the digital library community in order to make this repository more globally applicable to the storage and accessibility of research data.

\section*{Acknowledgments}

This work was supported by the National Science Foundation (BCS-1238599) and the National Institute of Child Health and Human Development (U01-HD-076595-01).
The authors gratefully acknowledge the NYU Libraries for their valuable advice and consultation.

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}
